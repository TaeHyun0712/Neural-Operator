{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["gi7pLsfsHfNj","zgqpuhSIHZJS","bO5EuVaoKjuH","Gf3dGvxO4K_p","zN5_zmpHJ_7y","5KgGYDPzKDrx"],"gpuType":"T4","authorship_tag":"ABX9TyOU21WNWiqjhHhSCnig/Qlz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Solve Partial Differential Equation with Physics-Informed Neural Operator(PINO)\n","\n","본 예제에서는 Physic-Informed Neural Operator(PINO)를 통해 Burger's Equation의 해를 계산하도록 훈련시키는 방법을 보여줍니다. 해당 코드는 \"Physics-Informed Neural Operator for Learning Partial Differential Equations\"의 Section 4.1의 예제 코드를 바탕으로 구성되었습니다. 추후 다른 예제 코드가 궁금하실 경우 본문 하단에 논문과 예제 코드의 참조 링크가 있으니, 참조 부탁 드립니다.\n","\n"," Burger's equation을 다양한 응용 수학에서 사용되는 편미분 방정식으로, 유체역학, 비선형 음향학, 기체 동역학 등 다양한 분야에서 사용됩니다. 해당 방정식의 구성은 아래와 같습니다.\n","\n","$$∂_tu(x, t) + ∂_x(u^2(x, t)/2) = ν∂_{xx} u(x, t),\\quad x ∈ (0, 1), t ∈ (0, 1]$$\n","$$u(x, 0) = u_0(x), \\quad x ∈ (0, 1)$$\n","\n","위의 방정식은 $u_0 ∈ L^2_{per}((0, 1); R)$의 주기적 경계 조건을 가지고 있습니다. $ν$는 점도 계수로 해당 예제에서는 0.01의 수치가 사용됩니다. 본 예제 코드는 초기 조건을 솔루션 $G_†: u_0 → u|_{[0,1]}.$에 매핑하는 연산자를 학습하는 것을 목표로 합니다.\n","\n","\n","\n","\n"],"metadata":{"id":"EkRhUy7u-PPa"}},{"cell_type":"markdown","source":["## Contact Google Drive"],"metadata":{"id":"gi7pLsfsHfNj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVLUraiB8Ugb"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd \"/content/drive/My Drive/PINO/physics_informed-master\""],"metadata":{"id":"5y3nEcc78qcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"pip install wandb\"\"\""],"metadata":{"id":"yStarFyHQZkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"import wandb\n","wandb.login()\"\"\""],"metadata":{"id":"6knaFDS8RAiu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generating Data"],"metadata":{"id":"zgqpuhSIHZJS"}},{"cell_type":"code","source":["#from argparse import ArgumentParser\n","import argparse\n","import yaml\n","import torch\n","#from models import FNO2d\n","from train_utils import Adam\n","#from train_utils.datasets import BurgersLoader\n","#from train_utils.train_2d import train_2d_burger\n","#from train_utils.eval_2d import eval_burgers\n","import scipy.io\n","import numpy as np"],"metadata":{"id":"R1obV8o838lI","executionInfo":{"status":"ok","timestamp":1691472797812,"user_tz":-540,"elapsed":12321,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class MatReader(object):\n","    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n","        super(MatReader, self).__init__()\n","\n","        self.to_torch = to_torch\n","        self.to_cuda = to_cuda\n","        self.to_float = to_float\n","\n","        self.file_path = file_path\n","\n","        self.data = None\n","        self.old_mat = None\n","        self._load_file()\n","\n","    def _load_file(self):\n","        self.data = scipy.io.loadmat(self.file_path)\n","        self.old_mat = True\n","\n","    def load_file(self, file_path):\n","        self.file_path = file_path\n","        self._load_file()\n","\n","    def read_field(self, field):\n","        x = self.data[field]\n","\n","        if not self.old_mat:\n","            x = x[()]\n","            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n","\n","        if self.to_float:\n","            x = x.astype(np.float32)\n","\n","        if self.to_torch:\n","            x = torch.from_numpy(x)\n","\n","            if self.to_cuda:\n","                x = x.cuda()\n","\n","        return x\n","\n","    def set_cuda(self, to_cuda):\n","        self.to_cuda = to_cuda\n","\n","    def set_torch(self, to_torch):\n","        self.to_torch = to_torch\n","\n","    def set_float(self, to_float):\n","        self.to_float = to_float\n","\n","\n","class BurgersLoader(object):\n","    def __init__(self, datapath, nx=2 ** 10, nt=100, sub=8, sub_t=1, new=False):\n","        dataloader = MatReader(datapath)\n","        self.sub = sub\n","        self.sub_t = sub_t\n","        self.s = nx // sub\n","        self.T = nt // sub_t\n","        self.new = new\n","        if new:\n","            self.T += 1\n","        self.x_data = dataloader.read_field('input')[:, ::sub]\n","        self.y_data = dataloader.read_field('output')[:, ::sub_t, ::sub]\n","        self.v = dataloader.read_field('visc').item()\n","\n","    def make_loader(self, n_sample, batch_size, start=0, train=True):\n","        Xs = self.x_data[start:start + n_sample]\n","        ys = self.y_data[start:start + n_sample]\n","\n","        if self.new:\n","            gridx = torch.tensor(np.linspace(0, 1, self.s + 1)[:-1], dtype=torch.float)\n","            gridt = torch.tensor(np.linspace(0, 1, self.T), dtype=torch.float)\n","        else:\n","            gridx = torch.tensor(np.linspace(0, 1, self.s), dtype=torch.float)\n","            gridt = torch.tensor(np.linspace(0, 1, self.T + 1)[1:], dtype=torch.float)\n","        gridx = gridx.reshape(1, 1, self.s)\n","        gridt = gridt.reshape(1, self.T, 1)\n","\n","        Xs = Xs.reshape(n_sample, 1, self.s).repeat([1, self.T, 1])\n","        Xs = torch.stack([Xs, gridx.repeat([n_sample, self.T, 1]), gridt.repeat([n_sample, 1, self.s])], dim=3)\n","        dataset = torch.utils.data.TensorDataset(Xs, ys)\n","        if train:\n","            loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","        else:\n","            loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","        return loader\n"],"metadata":{"id":"pXyBojYv4M7y","executionInfo":{"status":"ok","timestamp":1691472797812,"user_tz":-540,"elapsed":2,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Furier Neural Operator(FNO)"],"metadata":{"id":"bO5EuVaoKjuH"}},{"cell_type":"code","source":["import torch.nn as nn\n","from models.basics import SpectralConv2d\n","from models.utils import _get_act, add_padding2, remove_padding2\n","\n","\n","class FNO2d(nn.Module):\n","    def __init__(self, modes1, modes2,\n","                 width=64, fc_dim=128,\n","                 layers=None,\n","                 in_dim=3, out_dim=1,\n","                 act='gelu',\n","                 pad_ratio=[0., 0.]):\n","        super(FNO2d, self).__init__()\n","        \"\"\"\n","        Args:\n","            - modes1: list of int, number of modes in first dimension in each layer\n","            - modes2: list of int, number of modes in second dimension in each layer\n","            - width: int, optional, if layers is None, it will be initialized as [width] * [len(modes1) + 1]\n","            - in_dim: number of input channels\n","            - out_dim: number of output channels\n","            - act: activation function, {tanh, gelu, relu, leaky_relu}, default: gelu\n","            - pad_ratio: list of float, or float; portion of domain to be extended. If float, paddings are added to the right.\n","            If list, paddings are added to both sides. pad_ratio[0] pads left, pad_ratio[1] pads right.\n","        \"\"\"\n","        if isinstance(pad_ratio, float):\n","            pad_ratio = [pad_ratio, pad_ratio]\n","        else:\n","            assert len(pad_ratio) == 2, 'Cannot add padding in more than 2 directions'\n","        self.modes1 = modes1\n","        self.modes2 = modes2\n","\n","        self.pad_ratio = pad_ratio\n","        # input channel is 3: (a(x, y), x, y)\n","        if layers is None:\n","            self.layers = [width] * (len(modes1) + 1)\n","        else:\n","            self.layers = layers\n","        self.fc0 = nn.Linear(in_dim, layers[0])\n","\n","        self.sp_convs = nn.ModuleList([SpectralConv2d(\n","            in_size, out_size, mode1_num, mode2_num)\n","            for in_size, out_size, mode1_num, mode2_num\n","            in zip(self.layers, self.layers[1:], self.modes1, self.modes2)])\n","\n","        self.ws = nn.ModuleList([nn.Conv1d(in_size, out_size, 1)\n","                                 for in_size, out_size in zip(self.layers, self.layers[1:])])\n","\n","        self.fc1 = nn.Linear(layers[-1], fc_dim)\n","        self.fc2 = nn.Linear(fc_dim, layers[-1])\n","        self.fc3 = nn.Linear(layers[-1], out_dim)\n","        self.act = _get_act(act)\n","\n","    def forward(self, x):\n","        '''\n","        Args:\n","            - x : (batch size, x_grid, y_grid, 2)\n","        Returns:\n","            - x: (batch size, x_grid, y_grid, 1)\n","        '''\n","        size_1, size_2 = x.shape[1], x.shape[2]\n","        if max(self.pad_ratio) > 0:\n","            num_pad1 = [round(i * size_1) for i in self.pad_ratio]\n","            num_pad2 = [round(i * size_2) for i in self.pad_ratio]\n","        else:\n","            num_pad1 = num_pad2 = [0.]\n","\n","        length = len(self.ws)\n","        batchsize = x.shape[0]\n","        x = self.fc0(x)\n","        x = x.permute(0, 3, 1, 2)   # B, C, X, Y\n","        x = add_padding2(x, num_pad1, num_pad2)\n","        size_x, size_y = x.shape[-2], x.shape[-1]\n","\n","        for i, (speconv, w) in enumerate(zip(self.sp_convs, self.ws)):\n","            x1 = speconv(x)\n","            x2 = w(x.view(batchsize, self.layers[i], -1)).view(batchsize, self.layers[i+1], size_x, size_y)\n","            x = x1 + x2\n","            if i != length - 1:\n","                x = self.act(x)\n","        x = remove_padding2(x, num_pad1, num_pad2)\n","        x = x.permute(0, 2, 3, 1)\n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.fc2(x)\n","        x = self.act(x)\n","        x = self.fc3(x)\n","        return x\n"],"metadata":{"id":"2dC0UAa-KhYh","executionInfo":{"status":"ok","timestamp":1691472803331,"user_tz":-540,"elapsed":5520,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Defined Loss function"],"metadata":{"id":"Gf3dGvxO4K_p"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class LpLoss(object):\n","    '''\n","    loss function with rel/abs Lp loss\n","    '''\n","    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n","        super(LpLoss, self).__init__()\n","\n","        #Dimension and Lp-norm type are postive\n","        assert d > 0 and p > 0\n","\n","        self.d = d\n","        self.p = p\n","        self.reduction = reduction\n","        self.size_average = size_average\n","\n","    def abs(self, x, y):\n","        num_examples = x.size()[0]\n","\n","        #Assume uniform mesh\n","        h = 1.0 / (x.size()[1] - 1.0)\n","\n","        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n","\n","        if self.reduction:\n","            if self.size_average:\n","                return torch.mean(all_norms)\n","            else:\n","                return torch.sum(all_norms)\n","\n","        return all_norms\n","\n","    def rel(self, x, y):\n","        num_examples = x.size()[0]\n","\n","        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n","        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n","\n","        if self.reduction:\n","            if self.size_average:\n","                return torch.mean(diff_norms/y_norms)\n","            else:\n","                return torch.sum(diff_norms/y_norms)\n","\n","        return diff_norms/y_norms\n","\n","    def __call__(self, x, y):\n","        return self.rel(x, y)"],"metadata":{"id":"wXyL73hF4Pnh","executionInfo":{"status":"ok","timestamp":1691472803331,"user_tz":-540,"elapsed":9,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def FDM_Burgers(u, v, D=1):\n","    batchsize = u.size(0)\n","    nt = u.size(1)\n","    nx = u.size(2)\n","\n","    u = u.reshape(batchsize, nt, nx)\n","    dt = D / (nt-1)\n","    dx = D / (nx)\n","\n","    u_h = torch.fft.fft(u, dim=2)\n","    # Wavenumbers in y-direction\n","    k_max = nx//2\n","    k_x = torch.cat((torch.arange(start=0, end=k_max, step=1, device=u.device),\n","                     torch.arange(start=-k_max, end=0, step=1, device=u.device)), 0).reshape(1,1,nx)\n","    ux_h = 2j *np.pi*k_x*u_h\n","    uxx_h = 2j *np.pi*k_x*ux_h\n","    ux = torch.fft.irfft(ux_h[:, :, :k_max+1], dim=2, n=nx)\n","    uxx = torch.fft.irfft(uxx_h[:, :, :k_max+1], dim=2, n=nx)\n","    ut = (u[:, 2:, :] - u[:, :-2, :]) / (2 * dt)\n","    Du = ut + (ux*u - v*uxx)[:,1:-1,:]\n","    return Du"],"metadata":{"id":"9zV6e1G64dfj","executionInfo":{"status":"ok","timestamp":1691472803331,"user_tz":-540,"elapsed":8,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def PINO_loss(u, u0, v):\n","    batchsize = u.size(0)\n","    nt = u.size(1)\n","    nx = u.size(2)\n","\n","    u = u.reshape(batchsize, nt, nx)\n","    # lploss = LpLoss(size_average=True)\n","\n","    index_t = torch.zeros(nx,).long()\n","    index_x = torch.tensor(range(nx)).long()\n","    boundary_u = u[:, index_t, index_x]\n","    loss_u = F.mse_loss(boundary_u, u0)\n","\n","    Du = FDM_Burgers(u, v)[:, :, :]\n","    f = torch.zeros(Du.shape, device=u.device)\n","    loss_f = F.mse_loss(Du, f)\n","\n","    # loss_bc0 = F.mse_loss(u[:, :, 0], u[:, :, -1])\n","    # loss_bc1 = F.mse_loss((u[:, :, 1] - u[:, :, -1]) /\n","    #                       (2/(nx)), (u[:, :, 0] - u[:, :, -2])/(2/(nx)))\n","    return loss_u, loss_f"],"metadata":{"id":"MiRhk7Je4hK4","executionInfo":{"status":"ok","timestamp":1691472803332,"user_tz":-540,"elapsed":9,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Train Neural Operator"],"metadata":{"id":"zN5_zmpHJ_7y"}},{"cell_type":"code","source":["from train_utils.utils import save_checkpoint\n","from tqdm import tqdm\n","try:\n","    import wandb\n","except ImportError:\n","    wandb = None\n","\n","def train_2d_burger(model,\n","                    train_loader, v,\n","                    optimizer, scheduler,\n","                    config,\n","                    rank=0, log=False,\n","                    project='PINO-2d-default',\n","                    group='default',\n","                    tags=['default'],\n","                    use_tqdm=True):\n","    if rank == 0 and wandb and log:\n","        run = wandb.init(project=project,\n","                         entity=config['log']['entity'],\n","                         group=group,\n","                         config=config,\n","                         tags=tags, reinit=True,\n","                         settings=wandb.Settings(start_method=\"fork\"))\n","\n","    data_weight = config['train']['xy_loss']\n","    f_weight = config['train']['f_loss']\n","    ic_weight = config['train']['ic_loss']\n","    model.train()\n","    myloss = LpLoss(size_average=True)\n","    pbar = range(config['train']['epochs'])\n","    if use_tqdm:\n","        pbar = tqdm(pbar, dynamic_ncols=True, smoothing=0.1)\n","\n","    for e in pbar:\n","        model.train()\n","        train_pino = 0.0\n","        data_l2 = 0.0\n","        train_loss = 0.0\n","\n","        for x, y in train_loader:\n","            x, y = x.to(rank), y.to(rank)\n","            out = model(x).reshape(y.shape)\n","            data_loss = myloss(out, y)\n","\n","            loss_u, loss_f = PINO_loss(out, x[:, 0, :, 0], v)\n","            total_loss = loss_u * ic_weight + loss_f * f_weight + data_loss * data_weight\n","            optimizer.zero_grad()\n","            total_loss.backward()\n","            optimizer.step()\n","\n","            data_l2 += data_loss.item()\n","            train_pino += loss_f.item()\n","            train_loss += total_loss.item()\n","        scheduler.step()\n","        data_l2 /= len(train_loader)\n","        train_pino /= len(train_loader)\n","        train_loss /= len(train_loader)\n","        if use_tqdm:\n","            pbar.set_description(\n","                (\n","                    f'Epoch {e}, train loss: {train_loss:.5f} '\n","                    f'train f error: {train_pino:.5f}; '\n","                    f'data l2 error: {data_l2:.5f}'\n","                )\n","            )\n","        if wandb and log:\n","            wandb.log(\n","                {\n","                    'Train f error': train_pino,\n","                    'Train L2 error': data_l2,\n","                    'Train loss': train_loss,\n","                }\n","            )\n","\n","        if e % 10 == 0:\n","            save_checkpoint(config['train']['save_dir'],\n","                            config['train']['save_name'].replace('.pt', f'_{e}.pt'),\n","                            model, optimizer)\n","    save_checkpoint(config['train']['save_dir'],\n","                    config['train']['save_name'],\n","                    model, optimizer)\n","    print('Done!')"],"metadata":{"id":"UKdu3QHW37Yv","executionInfo":{"status":"ok","timestamp":1691472803332,"user_tz":-540,"elapsed":9,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def run(args, config):\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    data_config = config['data']\n","    dataset = BurgersLoader(data_config['datapath'],\n","                            nx=data_config['nx'], nt=data_config['nt'],\n","                            sub=data_config['sub'], sub_t=data_config['sub_t'], new=True)\n","    train_loader = dataset.make_loader(n_sample=data_config['n_sample'],\n","                                       batch_size=config['train']['batchsize'],\n","                                       start=data_config['offset'])\n","\n","    model = FNO2d(modes1=config['model']['modes1'],\n","                  modes2=config['model']['modes2'],\n","                  fc_dim=config['model']['fc_dim'],\n","                  layers=config['model']['layers'],\n","                  act=config['model']['act']).to(device)\n","    # Load from checkpoint\n","    if 'ckpt' in config['train']:\n","        ckpt_path = config['train']['ckpt']\n","        ckpt = torch.load(ckpt_path)\n","        model.load_state_dict(ckpt['model'])\n","        print('Weights loaded from %s' % ckpt_path)\n","    optimizer = Adam(model.parameters(), betas=(0.9, 0.999),\n","                     lr=config['train']['base_lr'])\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                     milestones=config['train']['milestones'],\n","                                                     gamma=config['train']['scheduler_gamma'])\n","    train_2d_burger(model,\n","                    train_loader,\n","                    dataset.v,\n","                    optimizer,\n","                    scheduler,\n","                    config,\n","                    rank=0,\n","                    log=args.log,\n","                    project=config['log']['project'],\n","                    group=config['log']['group'])\n"],"metadata":{"id":"RrRCgSMo1qd_","executionInfo":{"status":"ok","timestamp":1691472803332,"user_tz":-540,"elapsed":9,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    '''\n","    parser = ArgumentParser(description='Basic paser')\n","    parser.add_argument('--config_path', type=str, help='Path to the configuration file')\n","    parser.add_argument('--log', action='store_true', help='Turn on the wandb')\n","    parser.add_argument('--mode', type=str, help='train or test')\n","    args = parser.parse_args()\n","'''\n","    args = argparse.Namespace(\n","    config_path= \"configs/pretrain/burgers-pretrain.yaml\",\n","    log = 'store_true',\n","    mode=\"train\"\n","    )\n","\n","    config_file = args.config_path\n","    with open(config_file, 'r') as stream:\n","        config = yaml.load(stream, yaml.FullLoader)\n","    if args.mode == 'train':\n","        run(args, config)\n","    else:\n","        test(config)\n"],"metadata":{"id":"104ByvEBJvO1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test Neural Operator"],"metadata":{"id":"5KgGYDPzKDrx"}},{"cell_type":"code","source":["def eval_burgers(model,\n","                 dataloader,\n","                 v,\n","                 config,\n","                 device,\n","                 use_tqdm=True):\n","    model.eval()\n","    myloss = LpLoss(size_average=True)\n","    if use_tqdm:\n","        pbar = tqdm(dataloader, dynamic_ncols=True, smoothing=0.05)\n","    else:\n","        pbar = dataloader\n","\n","    test_err = []\n","    f_err = []\n","\n","    for x, y in pbar:\n","        x, y = x.to(device), y.to(device)\n","        out = model(x).reshape(y.shape)\n","        data_loss = myloss(out, y)\n","\n","        loss_u, f_loss = PINO_loss(out, x[:, 0, :, 0], v)\n","        test_err.append(data_loss.item())\n","        f_err.append(f_loss.item())\n","\n","    mean_f_err = np.mean(f_err)\n","    std_f_err = np.std(f_err, ddof=1) / np.sqrt(len(f_err))\n","\n","    mean_err = np.mean(test_err)\n","    std_err = np.std(test_err, ddof=1) / np.sqrt(len(test_err))\n","\n","    print(f'==Averaged relative L2 error mean: {mean_err}, std error: {std_err}==\\n'\n","          f'==Averaged equation error mean: {mean_f_err}, std error: {std_f_err}==')"],"metadata":{"id":"UZu8HIe15w4y","executionInfo":{"status":"ok","timestamp":1691474386700,"user_tz":-540,"elapsed":384,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def test(config):\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    data_config = config['data']\n","    dataset = BurgersLoader(data_config['datapath'],\n","                            nx=data_config['nx'], nt=data_config['nt'],\n","                            sub=data_config['sub'], sub_t=data_config['sub_t'], new=True)\n","    dataloader = dataset.make_loader(n_sample=data_config['n_sample'],\n","                                     batch_size=config['test']['batchsize'],\n","                                     start=data_config['offset'])\n","\n","    model = FNO2d(modes1=config['model']['modes1'],\n","                  modes2=config['model']['modes2'],\n","                  fc_dim=config['model']['fc_dim'],\n","                  layers=config['model']['layers'],\n","                  act=config['model']['act']).to(device)\n","    # Load from checkpoint\n","    if 'ckpt' in config['test']:\n","        ckpt_path = config['test']['ckpt']\n","        ckpt = torch.load(ckpt_path)\n","        model.load_state_dict(ckpt['model'])\n","        print('Weights loaded from %s' % ckpt_path)\n","    eval_burgers(model, dataloader, dataset.v, config, device)"],"metadata":{"id":"029TcTDo1uA_","executionInfo":{"status":"ok","timestamp":1691474387084,"user_tz":-540,"elapsed":1,"user":{"displayName":"윤태현/기계공학과","userId":"15541602153722409517"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    '''\n","    parser = ArgumentParser(description='Basic paser')\n","    parser.add_argument('--config_path', type=str, help='Path to the configuration file')\n","    parser.add_argument('--log', action='store_true', help='Turn on the wandb')\n","    parser.add_argument('--mode', type=str, help='train or test')\n","    args = parser.parse_args()\n","'''\n","    args = argparse.Namespace(\n","    config_path= \"configs/test/burgers.yaml\",\n","    log = 'store_true',\n","    mode=\"test\"\n","    )\n","\n","    config_file = args.config_path\n","    with open(config_file, 'r') as stream:\n","        config = yaml.load(stream, yaml.FullLoader)\n","    if args.mode == 'train':\n","        run(args, config)\n","    else:\n","        test(config)\n"],"metadata":{"id":"w_FfU35CxUAw"},"execution_count":null,"outputs":[]}]}